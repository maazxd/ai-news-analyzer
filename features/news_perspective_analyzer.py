"""
News Perspective Analyzer - Compare how different news sources with varying political biases report the same story
"""

import streamlit as st
import requests
import pandas as pd
import plotly.express as px
from datetime import datetime, timedelta
from collections import defaultdict
import re
from collections import Counter

from utils.helpers import get_secret_or_env
try:
    from utils.models import analyze_sentiment
except ImportError:
    # Fallback if models import fails
    def analyze_sentiment(text):
        return 0.0, 'neutral'

try:
    from utils.source_data import get_source_political_leaning
except ImportError:
    # Fallback if source_data import fails
    def get_source_political_leaning(url):
        return 'center'

# Bias color mapping
BIAS_COLORS = {
    'left': '#4285F4',     # Blue
    'center': '#34A853',   # Green  
    'right': '#EA4335'     # Red
}

def render_news_perspective_analyzer():
    """Main render function for News Perspective Analyzer"""
    st.title("News Perspective Analyzer")
    st.markdown("Compare how different news sources with varying political biases report the same story")
    
    # Main interface
    with st.form("perspective_form"):
        col1, col2 = st.columns([3, 1])
        
        with col1:
            topic = st.text_input(
                "Enter a news topic to analyze:",
                placeholder="e.g., Biden economy, Trump trial, climate change",
                help="Enter any current news topic to see how different political perspectives cover it"
            )
        
        with col2:
            submitted = st.form_submit_button("Analyze Perspectives", type="primary")
    
    if submitted and topic:
        analyze_news_perspective(topic)
    elif submitted and not topic:
        st.error("Please enter a topic to analyze")


def analyze_news_perspective(topic):
    """Analyze news perspective across political spectrum"""
    with st.spinner("Analyzing perspectives..."):
        # Collect articles from different bias categories
        articles_by_bias = collect_multi_source_articles(topic)
        
        # Combine all articles and analyze
        all_articles = []
        for bias_articles in articles_by_bias.values():
            all_articles.extend(bias_articles)
        
        if not all_articles:
            st.error("No articles found for this topic. Try a different search term.")
            return
        
        # Analyze sentiment and bias
        analyzed_articles = analyze_articles_sentiment_bias(articles_by_bias)
        
        # Display results
        bias_categories_found = len([bias for bias, articles in articles_by_bias.items() if articles])
        
        # Show visualizations and comparisons
        create_bias_spectrum_chart(analyzed_articles)
        create_side_by_side_comparison(analyzed_articles)
        analyze_key_differences(analyzed_articles)
        
        # Success message
        st.success(f"Analysis complete! Found {len(analyzed_articles)} articles across {bias_categories_found} perspectives.")


def collect_multi_source_articles(topic, max_per_bias=2):
    """Collect articles from different bias categories"""
    api_key = get_secret_or_env("NEWS_API_KEY")
    articles_by_bias = {'left': [], 'center': [], 'right': []}
    
    if not api_key:
        st.error("News API key not configured. Please check your environment settings.")
        return articles_by_bias
    
    progress_bar = st.progress(0)
    progress_text = st.empty()
    
    try:
        # Use general search first, then filter by domain
        url = "https://newsapi.org/v2/everything"
        params = {
            'q': topic,
            'sortBy': 'publishedAt',
            'pageSize': 50,  # Get more articles to filter from
            'language': 'en',
            'apiKey': api_key,
            'from': (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')  # Last 7 days
        }
        
        progress_text.text("Fetching articles from News API...")
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
        
        if not data.get('articles'):
            st.warning("No articles found for this topic from News API")
            progress_bar.empty()
            progress_text.empty()
            return articles_by_bias
        
        progress_text.text("Sorting articles by political bias...")
        
        # Categorize articles by source bias
        all_articles = data['articles']
        categorized_count = 0
        
        for article in all_articles:
            source_name = article.get('source', {}).get('name', '').lower()
            article_url = article.get('url', '').lower()
            
            # Determine bias category based on source
            bias_category = determine_source_bias(source_name, article_url)
            
            if bias_category and len(articles_by_bias[bias_category]) < max_per_bias:
                processed_article = process_article(article, bias_category)
                if processed_article:
                    articles_by_bias[bias_category].append(processed_article)
                    categorized_count += 1
            
            # Update progress
            progress = min(categorized_count / (max_per_bias * 3), 1.0)
            progress_bar.progress(progress)
            
            # Stop if we have enough articles from each category
            if all(len(articles_by_bias[bias]) >= max_per_bias for bias in ['left', 'center', 'right']):
                break
        
        progress_bar.empty()
        progress_text.empty()
        
        # Display collection summary
        total_articles = sum(len(articles) for articles in articles_by_bias.values())
        if total_articles > 0:
            st.success(f"Found {total_articles} articles across different perspectives")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Left-leaning", len(articles_by_bias['left']))
            with col2:
                st.metric("Center", len(articles_by_bias['center']))
            with col3:
                st.metric("Right-leaning", len(articles_by_bias['right']))
        else:
            st.warning("Could not categorize articles by political bias. Try a different topic.")
        
        return articles_by_bias
        
    except requests.RequestException as e:
        st.error(f"Network error: {str(e)}")
        progress_bar.empty()
        progress_text.empty()
        return articles_by_bias
    except Exception as e:
        st.error(f"Error collecting articles: {str(e)}")
        progress_bar.empty()
        progress_text.empty()
        return articles_by_bias


def determine_source_bias(source_name, article_url):
    """Determine political bias using the actual source database"""
    # Extract domain from URL for lookup
    domain = ""
    if article_url:
        try:
            from urllib.parse import urlparse
            domain = urlparse(article_url).netloc.lower()
            if domain.startswith('www.'):
                domain = domain[4:]
        except:
            pass
    
    # Use the actual source database
    political_leaning = get_source_political_leaning(domain)
    
    if political_leaning:
        if political_leaning == 'left-leaning':
            return 'left'
        elif political_leaning == 'right-leaning':
            return 'right'
        elif political_leaning == 'center':
            return 'center'
    
    return None


def process_article(article, bias_type):
    """Process and validate article data"""
    try:
        title = article.get('title', '').strip()
        description = article.get('description', '').strip()
        
        if not title or title == '[Removed]' or not description or description == '[Removed]':
            return None
        
        return {
            'title': title,
            'description': description,
            'url': article.get('url', ''),
            'source': article.get('source', {}).get('name', 'Unknown'),
            'bias_category': bias_type,
            'published_at': article.get('publishedAt', ''),
            'credibility': 'Medium'  # Default credibility
        }
    except Exception:
        return None


def analyze_articles_sentiment_bias(articles_by_bias):
    """Analyze sentiment and bias for all articles"""
    analyzed_articles = []
    
    progress_bar = st.progress(0)
    progress_text = st.empty()
    total_articles = sum(len(articles) for articles in articles_by_bias.values())
    processed = 0
    
    for bias_category, articles in articles_by_bias.items():
        for article in articles:
            progress_text.text(f"Analyzing sentiment for {article['source']}...")
            
            # Analyze sentiment
            text_to_analyze = f"{article['title']} {article['description']}"
            sentiment_result = analyze_sentiment_with_fallback(text_to_analyze)
            
            # Add analysis results
            article.update({
                'sentiment_score': sentiment_result.get('compound', 0),
                'sentiment_label': get_sentiment_label(sentiment_result.get('compound', 0)),
                'bias_score': get_bias_score(bias_category)
            })
            
            analyzed_articles.append(article)
            processed += 1
            progress_bar.progress(processed / total_articles)
    
    progress_bar.empty()
    progress_text.empty()
    
    return analyzed_articles


def analyze_sentiment_with_fallback(text):
    """Analyze sentiment with fallback methods"""
    try:
        # Try main sentiment analysis
        result = analyze_sentiment(text)
        
        # Validate result
        if isinstance(result, dict) and 'compound' in result:
            return result
        else:
            # Fallback to simple analysis
            return simple_sentiment_analysis(text)
    except Exception:
        # Fallback to simple analysis
        return simple_sentiment_analysis(text)


def simple_sentiment_analysis(text):
    """Simple sentiment analysis fallback"""
    positive_words = set(['good', 'great', 'excellent', 'positive', 'success', 'win', 'victory', 'achieve', 'improve', 'benefit', 'strong', 'effective', 'progress', 'growth', 'increase', 'rise', 'gain', 'advance', 'breakthrough', 'solution'])
    negative_words = set(['bad', 'terrible', 'negative', 'fail', 'failure', 'lose', 'loss', 'problem', 'issue', 'concern', 'crisis', 'decline', 'decrease', 'fall', 'drop', 'threat', 'risk', 'danger', 'difficult', 'challenge'])
    
    text_lower = text.lower()
    words = set(text_lower.split())
    
    positive_count = len(words.intersection(positive_words))
    negative_count = len(words.intersection(negative_words))
    
    if positive_count > negative_count:
        sentiment_score = min(0.5, positive_count * 0.1)
    elif negative_count > positive_count:
        sentiment_score = max(-0.5, -negative_count * 0.1)
    else:
        sentiment_score = 0.0
    
    return {
        'compound': sentiment_score,
        'pos': max(0, sentiment_score),
        'neu': 1 - abs(sentiment_score),
        'neg': max(0, -sentiment_score)
    }


def get_sentiment_label(score):
    """Get sentiment label from score"""
    if score > 0.1:
        return 'Positive'
    elif score < -0.1:
        return 'Negative'
    else:
        return 'Neutral'


def get_bias_score(bias_type):
    """Convert bias category to numerical score"""
    bias_scores = {'left': -1, 'center': 0, 'right': 1}
    return bias_scores.get(bias_type, 0)


def create_bias_spectrum_chart(articles):
    """Create bias vs sentiment chart"""
    st.subheader("Bias vs Sentiment Analysis")
    
    if not articles:
        st.warning("No articles to visualize")
        return
    
    df = pd.DataFrame(articles)
    
    # Create scatter plot
    fig = px.scatter(
        df,
        x='bias_score',
        y='sentiment_score',
        color='bias_category',
        size=[abs(score) * 10 + 8 for score in df['sentiment_score']],
        hover_data={
            'source': True,
            'credibility': True,
            'bias_score': False,
            'sentiment_score': ':.3f',
            'bias_category': False
        },
        hover_name='title',
        title="Political Bias vs Sentiment",
        labels={
            'bias_score': 'Political Bias',
            'sentiment_score': 'Sentiment Score',
            'bias_category': 'Source Type'
        },
        color_discrete_map=BIAS_COLORS,
        height=500
    )
    
    # Customize chart
    fig.update_layout(
        xaxis=dict(
            tickmode='array',
            tickvals=[-1, 0, 1],
            ticktext=['Left', 'Center', 'Right'],
            range=[-1.5, 1.5]
        ),
        yaxis=dict(
            title='Sentiment (Negative to Positive)',
            range=[-1.1, 1.1]
        ),
        showlegend=True,
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)'
    )
    
    # Add reference lines
    fig.add_hline(y=0, line_dash="dot", line_color="gray", opacity=0.5)
    fig.add_vline(x=0, line_dash="dot", line_color="gray", opacity=0.5)
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Quick insights
    if len(df) > 1:
        left_avg = df[df['bias_category'] == 'left']['sentiment_score'].mean() if len(df[df['bias_category'] == 'left']) > 0 else 0
        right_avg = df[df['bias_category'] == 'right']['sentiment_score'].mean() if len(df[df['bias_category'] == 'right']) > 0 else 0
        
        if abs(left_avg - right_avg) > 0.3:
            st.info(f"**Different viewpoints detected**: Left sources avg {left_avg:.2f}, Right sources avg {right_avg:.2f}")
        elif abs(left_avg - right_avg) < 0.2:
            st.success("**Similar coverage**: Most sources agree on this topic")
        else:
            st.warning("**Mixed coverage**: Sources show varied perspectives")


def create_side_by_side_comparison(articles):
    """Create side-by-side comparison of articles"""
    st.subheader("Source Comparison")
    
    if not articles:
        st.warning("No articles to compare")
        return
    
    # Group articles by bias category
    articles_by_bias = defaultdict(list)
    for article in articles:
        articles_by_bias[article['bias_category']].append(article)
    
    # Create comparison sections
    tabs = st.tabs(["Headlines", "Sentiment", "Details"])
    
    with tabs[0]:  # Headlines comparison
        st.write("**Compare how different sources frame the same story:**")
        
        for bias_type in ['left', 'center', 'right']:
            if articles_by_bias[bias_type]:
                st.markdown(f"### {bias_type.title()} Sources")
                for article in articles_by_bias[bias_type]:
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.markdown(f"**{article['source']}**: {article['title']}")
                    with col2:
                        st.markdown(f"{article['sentiment_label']} ({article['sentiment_score']:.2f})")
                st.divider()
    
    with tabs[1]:  # Sentiment comparison
        st.write("**Sentiment analysis by source:**")
        
        sentiment_data = []
        for article in articles:
            sentiment_data.append({
                'Source': article['source'],
                'Bias': article['bias_category'].title(),
                'Sentiment Score': article['sentiment_score'],
            })
        
        df_sentiment = pd.DataFrame(sentiment_data)
        
        # Create bar chart
        fig = px.bar(
            df_sentiment,
            x='Source',
            y='Sentiment Score',
            color='Bias',
            color_discrete_map=BIAS_COLORS,
            title="Sentiment by Source"
        )
        fig.update_layout(xaxis_tickangle=-45, height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    with tabs[2]:  # Details
        st.write("**Complete article details:**")
        
        for article in articles:
            with st.expander(f"{article['source']} - {article['title'][:50]}..."):
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.markdown(f"**Title**: {article['title']}")
                    if article.get('description'):
                        st.markdown(f"**Description**: {article['description']}")
                    st.markdown(f"[Read Full Article]({article['url']})")
                
                with col2:
                    st.markdown(f"**Bias**: {article['bias_category'].title()}")
                    st.markdown(f"**Sentiment**: {article['sentiment_label']} ({article['sentiment_score']:.2f})")
                    st.markdown(f"**Credibility**: {article['credibility']}")


def analyze_key_differences(articles):
    """Analyze and highlight key differences between sources"""
    st.subheader("Key Insights")
    
    if not articles:
        st.warning("No articles to analyze")
        return
    
    # Group by bias type
    articles_by_bias = defaultdict(list)
    for article in articles:
        articles_by_bias[article['bias_category']].append(article)
    
    # Quick stats
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Total Articles", len(articles))
    
    with col2:
        avg_sentiment = sum(a['sentiment_score'] for a in articles) / len(articles)
        st.metric("Average Sentiment", f"{avg_sentiment:.2f}")
    
    with col3:
        unique_sources = len(set(a['source'] for a in articles))
        st.metric("Unique Sources", unique_sources)
    
    # Coverage by bias
    st.subheader("Coverage Distribution")
    
    bias_stats = []
    for bias_type in ['left', 'center', 'right']:
        articles_count = len(articles_by_bias[bias_type])
        if articles_count > 0:
            avg_sentiment = sum(a['sentiment_score'] for a in articles_by_bias[bias_type]) / articles_count
            sources = ', '.join(set(a['source'] for a in articles_by_bias[bias_type]))
            bias_stats.append({
                'Political Leaning': bias_type.title(),
                'Articles': articles_count,
                'Avg Sentiment': f"{avg_sentiment:.2f}",
                'Sources': sources
            })
    
    if bias_stats:
        df_stats = pd.DataFrame(bias_stats)
        st.dataframe(df_stats, use_container_width=True, hide_index=True)
    
    # Key observations
    st.subheader("Key Observations")
    
    insights = []
    
    # Coverage balance
    coverage_counts = {bias: len(articles_by_bias[bias]) for bias in ['left', 'center', 'right']}
    max_coverage = max(coverage_counts.values())
    min_coverage = min(coverage_counts.values())
    
    if max_coverage > min_coverage:
        max_bias = max(coverage_counts, key=coverage_counts.get)
        insights.append(f"Most coverage from {max_bias} sources ({max_coverage} articles)")
    
    # Overall sentiment
    if avg_sentiment > 0.2:
        insights.append("Generally positive coverage across sources")
    elif avg_sentiment < -0.2:
        insights.append("Generally negative coverage across sources")
    else:
        insights.append("Mostly neutral coverage")
    
    # Display insights
    for insight in insights:
        st.info(f"• {insight}")
    
    # Reading tips
    with st.expander("Tips for Balanced Reading"):
        st.markdown("""
        **For a complete picture:**
        - Compare articles from different political perspectives
        - Notice differences in language and tone
        - Consider source credibility
        - Look for facts vs opinions
        - Identify what stories might be missing
        """)


def run_news_perspective_analyzer_feature(*args, **kwargs):
    """Wrapper function to match expected interface"""
    render_news_perspective_analyzer()


if __name__ == "__main__":
    run_news_perspective_analyzer_feature()